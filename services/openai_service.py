"""
OpenAI service for content generation, semantic reasoning, and alias matching.
Uses ChatGPT to provide helpful information about JUST University.
"""
import json
import time
from typing import Optional, Dict, Any, List, Tuple
from openai import OpenAI
from config import OPENAI_API_KEY, OPENAI_MODEL, MAX_RETRIES, RETRY_DELAY
from logger import get_logger


def retry_on_error(max_retries: int = None, delay: float = None):
    """Decorator for retrying failed API calls."""
    def decorator(func):
        def wrapper(*args, **kwargs):
            retries = max_retries or MAX_RETRIES
            wait = delay or RETRY_DELAY
            last_error = None
            
            for attempt in range(retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_error = e
                    if attempt < retries - 1:
                        time.sleep(wait * (attempt + 1))  # Exponential backoff
                    continue
            
            # Log final failure
            logger = get_logger()
            logger.error(f"{func.__name__} failed after {retries} attempts: {last_error}")
            return None
        return wrapper
    return decorator


class OpenAIService:
    """
    Handles all OpenAI operations including:
    - Knowledge-based search and information generation
    - Content generation for JUST University topics
    - Alias matching validation
    - Answer generation in Arabic and English
    
    Uses ChatGPT's knowledge to provide helpful information.
    """
    
    _instance = None
    
    def __new__(cls):
        """Singleton pattern."""
        if cls._instance is None:
            cls._instance = super(OpenAIService, cls).__new__(cls)
            cls._instance._initialize()
        return cls._instance
    
    def _initialize(self):
        """Initialize OpenAI client."""
        self.logger = get_logger()
        self.client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
        self.model = OPENAI_MODEL
        
        if self.client:
            self.logger.info(f"OpenAI service initialized with model: {self.model}")
        else:
            self.logger.warning("OpenAI API key not configured - web search disabled")
    
    def is_configured(self) -> bool:
        """Check if OpenAI is configured."""
        return self.client is not None
    
    # ========================================
    # ALIAS MATCHING VALIDATION (STEP 1)
    # ========================================
    
    def validate_alias_match(
        self, 
        query: str, 
        candidate_aliases: List[Dict[str, Any]],
        similarity_scores: List[float]
    ) -> Tuple[Optional[str], Optional[str], float]:
        """
        Use ChatGPT to validate or pick the best alias match.
        Called when cosine similarity is uncertain (below threshold).
        
        Args:
            query: User query
            candidate_aliases: List of {alias, canonical_key} candidates
            similarity_scores: Corresponding similarity scores
            
        Returns:
            Tuple of (best_alias, canonical_key, confidence)
            Returns (None, None, 0) if no match found
        """
        if not self.client or not candidate_aliases:
            return None, None, 0.0
        
        try:
            # Build candidates list for prompt
            candidates_text = "\n".join([
                f"- Alias: '{c['alias']}' â†’ Key: '{c['canonical_key']}' (similarity: {similarity_scores[i]:.2f})"
                for i, c in enumerate(candidate_aliases)
            ])
            
            prompt = f"""You are a semantic matching assistant for a university information system.

User Query: "{query}"

Candidate Aliases (with similarity scores):
{candidates_text}

TASK:
1. Analyze the user's query semantically
2. Determine which alias (if any) is the best match
3. Consider both semantic meaning and the similarity score

RULES:
- If a candidate clearly matches the query's intent, select it
- If no candidate matches, respond with "NO_MATCH"
- Be strict - only match if the semantic meaning aligns

Respond in JSON format:
{{
    "match": true/false,
    "selected_alias": "alias text or null",
    "canonical_key": "key or null",
    "confidence": 0.0-1.0,
    "reasoning": "brief explanation"
}}"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a semantic matching expert. Analyze queries and determine the best alias match."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            if result.get('match') and result.get('canonical_key'):
                self.logger.info(
                    f"ChatGPT validated match: '{query}' -> '{result['selected_alias']}' "
                    f"(key: {result['canonical_key']}, confidence: {result['confidence']})"
                )
                return (
                    result.get('selected_alias'),
                    result.get('canonical_key'),
                    result.get('confidence', 0.8)
                )
            else:
                self.logger.info(f"ChatGPT found no match for: '{query}'")
                return None, None, 0.0
                
        except Exception as e:
            self.logger.error(f"Alias validation failed: {e}")
            return None, None, 0.0
    
    def select_best_resource(
        self, 
        query: str, 
        resources: Dict[str, str]
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        Use ChatGPT to select the best resource URL for a query.
        
        Args:
            query: User query
            resources: Dict of {key: url}
            
        Returns:
            Tuple of (resource_key, url) or (None, None)
        """
        if not self.client or not resources:
            return None, None
        
        try:
            resources_text = "\n".join([
                f"- {key}: {url}" for key, url in resources.items()
            ])
            
            prompt = f"""You are a resource selector for a university information system.

User Query: "{query}"

Available Resources:
{resources_text}

TASK:
Select the most appropriate resource URL for this query.
If no resource matches, respond with null.

Respond in JSON:
{{
    "selected_key": "key or null",
    "selected_url": "url or null",
    "reasoning": "brief explanation"
}}"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a resource selector. Match queries to the most relevant university resource."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            if result.get('selected_url'):
                self.logger.info(f"Selected resource: {result['selected_key']} for query: '{query}'")
                return result.get('selected_key'), result.get('selected_url')
            
            return None, None
            
        except Exception as e:
            self.logger.error(f"Resource selection failed: {e}")
            return None, None
    
    # ========================================
    # WEB SEARCH OPERATIONS
    # ========================================
    
    def perform_web_search(self, query: str) -> Optional[str]:
        """
        Perform a search about JUST university using ChatGPT.
        Uses model's knowledge and provides helpful information.
        
        Args:
            query: The search query
            
        Returns:
            Search results as text, or None if failed
        """
        if not self.client:
            self.logger.warning("OpenAI client not configured")
            return None
        
        try:
            self.logger.info(f"Performing search for: {query}")
            
            # Use chat completion with specialized prompt for JUST
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© (JUST) - Jordan University of Science and Technology.

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©:
- Ø§Ù„Ù…ÙˆÙ‚Ø¹: Ø¥Ø±Ø¨Ø¯ØŒ Ø§Ù„Ø£Ø±Ø¯Ù†
- ØªØ£Ø³Ø³Øª: 1986
- Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ: https://www.just.edu.jo
- Ù…Ù† Ø£ÙƒØ¨Ø± Ø§Ù„Ø¬Ø§Ù…Ø¹Ø§Øª Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© ÙˆØ£ÙØ¶Ù„Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø¹Ù„Ù…ÙŠØ© ÙˆØ§Ù„ØªÙ‚Ù†ÙŠØ©

Ø§Ù„ÙƒÙ„ÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
- ÙƒÙ„ÙŠØ© Ø§Ù„Ø·Ø¨
- ÙƒÙ„ÙŠØ© Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©
- ÙƒÙ„ÙŠØ© ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³ÙˆØ¨
- ÙƒÙ„ÙŠØ© Ø§Ù„ØµÙŠØ¯Ù„Ø©
- ÙƒÙ„ÙŠØ© Ø·Ø¨ Ø§Ù„Ø£Ø³Ù†Ø§Ù†
- ÙƒÙ„ÙŠØ© Ø§Ù„ØªÙ…Ø±ÙŠØ¶
- ÙƒÙ„ÙŠØ© Ø§Ù„Ø¹Ù„ÙˆÙ…
- ÙƒÙ„ÙŠØ© Ø§Ù„Ø²Ø±Ø§Ø¹Ø©
- ÙƒÙ„ÙŠØ© Ø§Ù„Ø¹Ù…Ø§Ø±Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…

Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨:
- Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„Ù‚Ø¨ÙˆÙ„
- Ø§Ù„Ø³ÙƒÙ† Ø§Ù„Ø¬Ø§Ù…Ø¹ÙŠ
- Ø§Ù„Ù…ÙƒØªØ¨Ø©
- Ø§Ù„Ù…Ù†Ø­ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©
- Ø´Ø¤ÙˆÙ† Ø§Ù„Ø·Ù„Ø§Ø¨

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
1. Ø£Ø¬Ø¨ Ø¨Ø´ÙƒÙ„ Ù…ÙÙŠØ¯ ÙˆÙ…ÙØµÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø¹Ø±ÙØªÙƒ
2. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯Ø¯Ø© (Ø±Ø³ÙˆÙ…ØŒ Ù…ÙˆØ§Ø¹ÙŠØ¯)ØŒ Ø§Ù‚ØªØ±Ø­ Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ
3. ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ø³Ø§Ø¹Ø¯Ø§Ù‹
4. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø­Ø³Ø¨ Ù„ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„"""
                    },
                    {
                        "role": "user",
                        "content": f"Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ©:\n\n{query}"
                    }
                ]
            )
            
            result = response.choices[0].message.content
            self.logger.debug(f"Search completed, result length: {len(result) if result else 0}")
            return result
            
        except Exception as e:
            self.logger.error(f"Search failed: {e}")
            return None
    
    def extract_page_data(self, url: str, query: str) -> Optional[Dict[str, Any]]:
        """
        Generate structured data for a topic using ChatGPT.
        
        Args:
            url: Context URL (may not be directly accessible)
            query: The original query for context
            
        Returns:
            Structured JSON dataset or None if failed
        """
        if not self.client:
            self.logger.warning("OpenAI client not configured")
            return None
        
        try:
            self.logger.info(f"Generating data for query: {query}")
            
            extraction_prompt = f"""Ø£Ù†Ø´Ø¦ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ©:

Ø§Ù„Ø³Ø¤Ø§Ù„: "{query}"
Ø±Ø§Ø¨Ø· Ù…Ø±Ø¬Ø¹ÙŠ: {url}

Ø£Ø±Ø¬Ø¹ ÙƒØ§Ø¦Ù† JSON Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø­Ù‚ÙˆÙ„ (Ø£Ø¶Ù ÙÙ‚Ø· Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©):
{{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹",
    "summary": "Ù…Ù„Ø®Øµ Ù…ÙÙŠØ¯ (300-500 Ø­Ø±Ù)",
    "key_points": ["Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"],
    "steps": ["Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¹Ù…Ù„ÙŠØ©"],
    "tips": ["Ù†ØµØ§Ø¦Ø­ Ù…ÙÙŠØ¯Ø©"],
    "website": "Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
    "contact": "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø¥Ø°Ø§ Ù…Ø¹Ø±ÙˆÙØ©"
}}

Ù…Ù„Ø§Ø­Ø¸Ø§Øª:
- Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© ÙˆØ¹Ø§Ù…Ø© Ø¹Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
- Ø§Ù‚ØªØ±Ø­ Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ Ù„Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© (Ø§Ù„Ø±Ø³ÙˆÙ…ØŒ Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯)
- Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ: https://www.just.edu.jo"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© (JUST).
Ù…Ù‡Ù…ØªÙƒ ØªÙ‚Ø¯ÙŠÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ù„Ø§Ø¨.

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
- Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø© Ù…ÙÙŠØ¯Ø©
- Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© (Ø±Ø³ÙˆÙ…ØŒ Ù…ÙˆØ§Ø¹ÙŠØ¯) Ø§Ù‚ØªØ±Ø­ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ
- Ø£Ø±Ø¬Ø¹ JSON ØµØ§Ù„Ø­ ÙÙ‚Ø·
- ÙƒÙ† Ù…Ø³Ø§Ø¹Ø¯Ø§Ù‹ ÙˆÙˆØ¯ÙˆØ¯Ø§Ù‹"""
                    },
                    {
                        "role": "user",
                        "content": extraction_prompt
                    }
                ],
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content
            
            if not content:
                self.logger.warning("Empty response from extraction")
                return None
            
            # Parse JSON response
            try:
                data = json.loads(content)
            except json.JSONDecodeError:
                data = self._extract_json_from_text(content)
            
            if data:
                data['url'] = url
                data['source_query'] = query
                data = {k: v for k, v in data.items() if v is not None and v != "" and v != [] and v != {}}
                self.logger.info(f"Generated {len(data)} fields for: {query}")
                return data
            
            return None
            
        except Exception as e:
            self.logger.error(f"Data generation failed for {query}: {e}")
            return None
    
    def _extract_json_from_text(self, text: str) -> Optional[Dict[str, Any]]:
        """Extract JSON from text that might contain markdown or other content."""
        import re
        
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass
        
        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            try:
                return json.loads(json_match.group(0))
            except json.JSONDecodeError:
                pass
        
        return None
    
    # ========================================
    # ANSWER GENERATION
    # ========================================
    
    def generate_answer(self, json_data: Dict[str, Any], query: str, source: str) -> str:
        """
        Generate a VERY DETAILED natural-language answer from JSON data.
        
        Args:
            json_data: The structured JSON dataset
            query: Original student query
            source: Data source ("redis" or "live_web")
            
        Returns:
            Very detailed, comprehensive student-friendly explanation
        """
        if not self.client:
            return self._generate_fallback_answer(json_data, query)
        
        try:
            # Check data source for context
            is_cached = (source == "redis")
            source_note = "ðŸ“¦ Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ - Ù‚Ù… Ø¨ØªÙˆØ³ÙŠØ¹Ù‡Ø§ ÙˆØ¥Ø«Ø±Ø§Ø¦Ù‡Ø§ Ø¨Ù…Ø¹Ø±ÙØªÙƒ" if is_cached else "ðŸŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©"
            
            prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© (JUST).
Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ø§Ù„Ø¨.

{source_note}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨: "{query}"

Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:
{json.dumps(json_data, indent=2, ensure_ascii=False)}

ðŸŽ¯ Ù…Ù‡Ù…ØªÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙƒØ£Ø³Ø§Ø³
- Ø£Ø¶Ù ØªÙØ§ØµÙŠÙ„ ÙˆØ´Ø±ÙˆØ­Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† Ù…Ø¹Ø±ÙØªÙƒ Ø¹Ù† Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©
- ÙˆØ³Ù‘Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù„ØªÙƒÙˆÙ† Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹
- Ù„Ø§ ØªÙƒØªÙÙ Ø¨Ù†Ù‚Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø§Ø´Ø±Ø­Ù‡Ø§ ÙˆÙØµÙ‘Ù„Ù‡Ø§

âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹:

ðŸ“‹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„ÙƒØ§Ù…Ù„Ø© (Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹!):
- Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¹Ù† Ù‚Ø§Ø¦Ù…Ø© (ØªØ®ØµØµØ§ØªØŒ ÙƒÙ„ÙŠØ§ØªØŒ Ø¨Ø±Ø§Ù…Ø¬ØŒ Ù…ØªØ·Ù„Ø¨Ø§ØªØŒ Ù…ÙˆØ§Ø¯) ÙŠØ¬Ø¨ Ø°ÙƒØ± Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙƒØ§Ù…Ù„Ø©
- Ù„Ø§ ØªÙ‚Ù„ "ÙˆØºÙŠØ±Ù‡Ø§" Ø£Ùˆ "ÙˆØ§Ù„Ù…Ø²ÙŠØ¯" Ø£Ùˆ "Ù…Ø«Ù„" Ø«Ù… ØªØ°ÙƒØ± 2-3 ÙÙ‚Ø·
- Ø§Ø°ÙƒØ± ÙƒÙ„ Ø¹Ù†ØµØ± ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„
- Ø¥Ø°Ø§ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø©ØŒ Ø§Ø¹Ø±Ø¶Ù‡Ø§ ÙƒØ§Ù…Ù„Ø© Ø«Ù… Ø§Ø´Ø±Ø­ ÙƒÙ„ Ø¹Ù†ØµØ±

ðŸ“ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙˆØ§Ù„ØªÙØµÙŠÙ„:
1. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹ ÙˆØ´Ø§Ù…Ù„Ø© (500+ ÙƒÙ„Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„)
2. Ø§Ø´Ø±Ø­ ÙƒÙ„ Ù†Ù‚Ø·Ø© Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙØµÙ„ Ù…Ø¹ Ø£Ù…Ø«Ù„Ø©
3. Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù†Ø§ÙˆÙŠÙ† ÙØ±Ø¹ÙŠØ© (##)ØŒ Ù†Ù‚Ø§Ø· (-)ØŒ ÙˆÙ‚ÙˆØ§Ø¦Ù… Ù…Ø±Ù‚Ù…Ø©
4. Ø£Ø¶Ù Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…ÙÙŠØ¯Ø© Ù…Ù† Ù…Ø¹Ø±ÙØªÙƒ Ø¹Ù† JUST
5. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø®Ø·ÙˆØ§ØªØŒ Ø§Ø´Ø±Ø­ ÙƒÙ„ Ø®Ø·ÙˆØ© Ø¨Ø§Ù„ØªÙØµÙŠÙ„
6. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø±Ø³ÙˆÙ… Ø£Ùˆ ØªÙƒØ§Ù„ÙŠÙØŒ Ø§Ø´Ø±Ø­Ù‡Ø§ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ù…Ø¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
7. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ù…ØªØ·Ù„Ø¨Ø§ØªØŒ Ø§Ø´Ø±Ø­ ÙƒÙ„ Ù…ØªØ·Ù„Ø¨ Ø¹Ù„Ù‰ Ø­Ø¯Ø©
8. Ø£Ø¶Ù Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ© ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ø§Ù„Ø¨
9. Ø§Ù‚ØªØ±Ø­ Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ: https://www.just.edu.jo

ðŸš« Ù…Ù…Ù†ÙˆØ¹:
- Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© (RedisØŒ cachingØŒ embeddingsØŒ cache)
- Ù„Ø§ ØªØ®ØªØµØ± Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø£Ùˆ ØªÙ‚ÙˆÙ„ "ÙˆØºÙŠØ±Ù‡Ø§"
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… "Ù…Ø«Ù„" Ù„Ù„Ø§Ø®ØªØµØ§Ø±
- Ù„Ø§ ØªÙ‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù‚ØµÙŠØ±Ø© Ø£Ùˆ Ø³Ø·Ø­ÙŠØ©

âœ… Ù…Ø·Ù„ÙˆØ¨:
- ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆÙ…Ù‡ØªÙ…Ø§Ù‹ Ø¨Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ø§Ù„Ø¨
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ ÙˆÙˆØ§Ø¶Ø­
- Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§Ù…Ù„Ø© ÙˆØ´Ø§Ù…Ù„Ø© ÙˆÙ…ÙØµÙ„Ø©
- Ø£Ø¶Ù Ù‚ÙŠÙ…Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù„Ø·Ø§Ù„Ø¨ Ø¨Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©

Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹ ØªØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø³Ø¤Ø§Ù„."""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© (JUST).
Ù…Ù‡Ù…ØªÙƒ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ù„Ø§Ø¨.

Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© ÙŠØ¬Ø¨ Ø§ØªØ¨Ø§Ø¹Ù‡Ø§ Ø¯Ø§Ø¦Ù…Ø§Ù‹:
1. ÙƒÙ† Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ - Ø¥Ø¬Ø§Ø¨Ø§Øª Ø·ÙˆÙŠÙ„Ø© ÙˆÙ…ÙÙŠØ¯Ø© (500+ ÙƒÙ„Ù…Ø©)
2. Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø¹Ù† Ù‚Ø§Ø¦Ù…Ø© (ØªØ®ØµØµØ§ØªØŒ ÙƒÙ„ÙŠØ§ØªØŒ Ø¨Ø±Ø§Ù…Ø¬ØŒ Ù…ÙˆØ§Ø¯) Ø§Ø°ÙƒØ± Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙƒØ§Ù…Ù„Ø© Ø¨Ø§Ù„ØªÙØµÙŠÙ„
3. Ù„Ø§ ØªÙ‚Ù„ Ø£Ø¨Ø¯Ø§Ù‹ "ÙˆØºÙŠØ±Ù‡Ø§" Ø£Ùˆ "Ù…Ø«Ù„" Ø£Ùˆ "ÙˆØ§Ù„Ù…Ø²ÙŠØ¯" - Ø§Ø°ÙƒØ± ÙƒÙ„ Ø´ÙŠØ¡
4. Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø¸ÙŠÙ… ÙˆØ§Ø¶Ø­ Ù…Ø¹ Ø¹Ù†Ø§ÙˆÙŠÙ† (##) ÙˆÙ†Ù‚Ø§Ø· (-) ÙˆÙ‚ÙˆØ§Ø¦Ù… Ù…Ø±Ù‚Ù…Ø©
5. Ø£Ø¶Ù Ø´Ø±ÙˆØ­Ø§Øª ÙˆØ£Ù…Ø«Ù„Ø© ÙˆØªÙˆØ¶ÙŠØ­Ø§Øª Ø¹Ù…Ù„ÙŠØ©
6. Ø£Ø¶Ù Ù†ØµØ§Ø¦Ø­ Ù…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ø§Ù„Ø¨
7. ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ù‡ØªÙ…Ø§Ù‹ Ø¨Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ù„Ø§Ø¨
8. Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø±ÙØªÙƒ Ø¹Ù† Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ù„Ø¥Ø«Ø±Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
9. Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© Ù…Ø«Ù„ cache Ø£Ùˆ Redis"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=4000  # Increased for longer, more complete answers
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            self.logger.error(f"Answer generation failed: {e}")
            return self._generate_fallback_answer(json_data, query)
    
    def generate_answer_stream(self, json_data: Dict[str, Any], query: str, source: str):
        """
        Generate a streaming answer from JSON data.
        Yields chunks of text as they are generated.
        
        Args:
            json_data: The structured JSON dataset
            query: Original student query
            source: Data source ("redis" or "live_web")
            
        Yields:
            Text chunks as they are generated
        """
        if not self.client:
            # Fallback: yield the fallback answer all at once
            fallback = self._generate_fallback_answer(json_data, query)
            yield fallback
            return
        
        try:
            # Check data source for context
            is_cached = (source == "redis")
            source_note = "ðŸ“¦ Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ - Ù‚Ù… Ø¨ØªÙˆØ³ÙŠØ¹Ù‡Ø§ ÙˆØ¥Ø«Ø±Ø§Ø¦Ù‡Ø§ Ø¨Ù…Ø¹Ø±ÙØªÙƒ" if is_cached else "ðŸŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©"
            
            prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© (JUST).
Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ø§Ù„Ø¨.

{source_note}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨: "{query}"

Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:
{json.dumps(json_data, indent=2, ensure_ascii=False)}

ðŸŽ¯ Ù…Ù‡Ù…ØªÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙƒØ£Ø³Ø§Ø³
- Ø£Ø¶Ù ØªÙØ§ØµÙŠÙ„ ÙˆØ´Ø±ÙˆØ­Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† Ù…Ø¹Ø±ÙØªÙƒ Ø¹Ù† Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©
- ÙˆØ³Ù‘Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù„ØªÙƒÙˆÙ† Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹
- Ù„Ø§ ØªÙƒØªÙÙ Ø¨Ù†Ù‚Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø§Ø´Ø±Ø­Ù‡Ø§ ÙˆÙØµÙ‘Ù„Ù‡Ø§

âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹:

ðŸ“‹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„ÙƒØ§Ù…Ù„Ø© (Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹!):
- Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¹Ù† Ù‚Ø§Ø¦Ù…Ø© (ØªØ®ØµØµØ§ØªØŒ ÙƒÙ„ÙŠØ§ØªØŒ Ø¨Ø±Ø§Ù…Ø¬ØŒ Ù…ØªØ·Ù„Ø¨Ø§ØªØŒ Ù…ÙˆØ§Ø¯) ÙŠØ¬Ø¨ Ø°ÙƒØ± Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙƒØ§Ù…Ù„Ø©
- Ù„Ø§ ØªÙ‚Ù„ "ÙˆØºÙŠØ±Ù‡Ø§" Ø£Ùˆ "ÙˆØ§Ù„Ù…Ø²ÙŠØ¯" Ø£Ùˆ "Ù…Ø«Ù„" Ø«Ù… ØªØ°ÙƒØ± 2-3 ÙÙ‚Ø·
- Ø§Ø°ÙƒØ± ÙƒÙ„ Ø¹Ù†ØµØ± ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„
- Ø¥Ø°Ø§ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø©ØŒ Ø§Ø¹Ø±Ø¶Ù‡Ø§ ÙƒØ§Ù…Ù„Ø© Ø«Ù… Ø§Ø´Ø±Ø­ ÙƒÙ„ Ø¹Ù†ØµØ±

ðŸ“ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙˆØ§Ù„ØªÙØµÙŠÙ„:
1. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹ ÙˆØ´Ø§Ù…Ù„Ø© (500+ ÙƒÙ„Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„)
2. Ø§Ø´Ø±Ø­ ÙƒÙ„ Ù†Ù‚Ø·Ø© Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙØµÙ„ Ù…Ø¹ Ø£Ù…Ø«Ù„Ø©
3. Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù†Ø§ÙˆÙŠÙ† ÙØ±Ø¹ÙŠØ© (##)ØŒ Ù†Ù‚Ø§Ø· (-)ØŒ ÙˆÙ‚ÙˆØ§Ø¦Ù… Ù…Ø±Ù‚Ù…Ø©
4. Ø£Ø¶Ù Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…ÙÙŠØ¯Ø© Ù…Ù† Ù…Ø¹Ø±ÙØªÙƒ Ø¹Ù† JUST
5. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø®Ø·ÙˆØ§ØªØŒ Ø§Ø´Ø±Ø­ ÙƒÙ„ Ø®Ø·ÙˆØ© Ø¨Ø§Ù„ØªÙØµÙŠÙ„
6. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø±Ø³ÙˆÙ… Ø£Ùˆ ØªÙƒØ§Ù„ÙŠÙØŒ Ø§Ø´Ø±Ø­Ù‡Ø§ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ù…Ø¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
7. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ù…ØªØ·Ù„Ø¨Ø§ØªØŒ Ø§Ø´Ø±Ø­ ÙƒÙ„ Ù…ØªØ·Ù„Ø¨ Ø¹Ù„Ù‰ Ø­Ø¯Ø©
8. Ø£Ø¶Ù Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ© ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ø§Ù„Ø¨
9. Ø§Ù‚ØªØ±Ø­ Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ: https://www.just.edu.jo

ðŸš« Ù…Ù…Ù†ÙˆØ¹:
- Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© (RedisØŒ cachingØŒ embeddingsØŒ cache)
- Ù„Ø§ ØªØ®ØªØµØ± Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø£Ùˆ ØªÙ‚ÙˆÙ„ "ÙˆØºÙŠØ±Ù‡Ø§"
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… "Ù…Ø«Ù„" Ù„Ù„Ø§Ø®ØªØµØ§Ø±
- Ù„Ø§ ØªÙ‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù‚ØµÙŠØ±Ø© Ø£Ùˆ Ø³Ø·Ø­ÙŠØ©

âœ… Ù…Ø·Ù„ÙˆØ¨:
- ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆÙ…Ù‡ØªÙ…Ø§Ù‹ Ø¨Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ø§Ù„Ø¨
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ ÙˆÙˆØ§Ø¶Ø­
- Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§Ù…Ù„Ø© ÙˆØ´Ø§Ù…Ù„Ø© ÙˆÙ…ÙØµÙ„Ø©
- Ø£Ø¶Ù Ù‚ÙŠÙ…Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù„Ø·Ø§Ù„Ø¨ Ø¨Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©

Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹ ØªØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø³Ø¤Ø§Ù„."""

            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© (JUST).
Ù…Ù‡Ù…ØªÙƒ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙØµÙ„Ø© Ø¬Ø¯Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ù„Ø§Ø¨.

Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© ÙŠØ¬Ø¨ Ø§ØªØ¨Ø§Ø¹Ù‡Ø§ Ø¯Ø§Ø¦Ù…Ø§Ù‹:
1. ÙƒÙ† Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ - Ø¥Ø¬Ø§Ø¨Ø§Øª Ø·ÙˆÙŠÙ„Ø© ÙˆÙ…ÙÙŠØ¯Ø© (500+ ÙƒÙ„Ù…Ø©)
2. Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø¹Ù† Ù‚Ø§Ø¦Ù…Ø© (ØªØ®ØµØµØ§ØªØŒ ÙƒÙ„ÙŠØ§ØªØŒ Ø¨Ø±Ø§Ù…Ø¬ØŒ Ù…ÙˆØ§Ø¯) Ø§Ø°ÙƒØ± Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙƒØ§Ù…Ù„Ø© Ø¨Ø§Ù„ØªÙØµÙŠÙ„
3. Ù„Ø§ ØªÙ‚Ù„ Ø£Ø¨Ø¯Ø§Ù‹ "ÙˆØºÙŠØ±Ù‡Ø§" Ø£Ùˆ "Ù…Ø«Ù„" Ø£Ùˆ "ÙˆØ§Ù„Ù…Ø²ÙŠØ¯" - Ø§Ø°ÙƒØ± ÙƒÙ„ Ø´ÙŠØ¡
4. Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø¸ÙŠÙ… ÙˆØ§Ø¶Ø­ Ù…Ø¹ Ø¹Ù†Ø§ÙˆÙŠÙ† (##) ÙˆÙ†Ù‚Ø§Ø· (-) ÙˆÙ‚ÙˆØ§Ø¦Ù… Ù…Ø±Ù‚Ù…Ø©
5. Ø£Ø¶Ù Ø´Ø±ÙˆØ­Ø§Øª ÙˆØ£Ù…Ø«Ù„Ø© ÙˆØªÙˆØ¶ÙŠØ­Ø§Øª Ø¹Ù…Ù„ÙŠØ©
6. Ø£Ø¶Ù Ù†ØµØ§Ø¦Ø­ Ù…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ø§Ù„Ø¨
7. ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ù‡ØªÙ…Ø§Ù‹ Ø¨Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ù„Ø§Ø¨
8. Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø±ÙØªÙƒ Ø¹Ù† Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ù„Ø¥Ø«Ø±Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
9. Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© Ù…Ø«Ù„ cache Ø£Ùˆ Redis"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=4000,  # Increased for longer, more complete answers
                stream=True  # Enable streaming
            )
            
            # Yield chunks as they arrive
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            self.logger.error(f"Streaming answer generation failed: {e}")
            # Fallback: yield the fallback answer
            fallback = self._generate_fallback_answer(json_data, query)
            yield fallback
    
    def _generate_fallback_answer(self, json_data: Dict[str, Any], query: str) -> str:
        """Generate a basic answer without AI."""
        parts = ["Here's the information you're looking for:\n"]
        
        if json_data.get('title'):
            parts.append(f"**{json_data['title']}**\n")
        
        if json_data.get('summary'):
            parts.append(f"{json_data['summary']}\n")
        
        if json_data.get('requirements'):
            parts.append("\n**Requirements:**")
            for req in json_data['requirements']:
                parts.append(f"â€¢ {req}")
        
        if json_data.get('fees'):
            parts.append("\n**Fees:**")
            for key, value in json_data['fees'].items():
                parts.append(f"â€¢ {key}: {value}")
        
        if json_data.get('steps'):
            parts.append("\n**Steps:**")
            for i, step in enumerate(json_data['steps'], 1):
                parts.append(f"{i}. {step}")
        
        if json_data.get('deadlines'):
            parts.append("\n**Deadlines:**")
            for deadline in json_data['deadlines']:
                parts.append(f"â€¢ {deadline}")
        
        if json_data.get('url'):
            parts.append(f"\nFor more details, visit: {json_data['url']}")
        
        return "\n".join(parts)
    
    # ========================================
    # ALIAS GENERATION
    # ========================================
    
    def generate_aliases_with_ai(self, canonical_key: str, query: str) -> List[str]:
        """
        Generate exactly 10 English + 10 Arabic aliases for a canonical key.
        
        Args:
            canonical_key: The canonical key
            query: The original query
            
        Returns:
            List of 20 aliases (10 Arabic + 10 English)
        """
        if not self.client:
            return []
        
        try:
            prompt = f"""Ø£Ù†Øª Ù…ÙˆÙ„Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªØ¹Ø§Ø±Ø© Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© (JUST).

Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {canonical_key}
Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ØµÙ„ÙŠ: "{query}"

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: ØªÙˆÙ„ÙŠØ¯ 20 Ø§Ø³Ù… Ù…Ø³ØªØ¹Ø§Ø± Ø¨Ø§Ù„Ø¶Ø¨Ø·:

10 Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªØ¹Ø§Ø±Ø© Ø¹Ø±Ø¨ÙŠØ©:
- 3 Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰
- 3 Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ©/Ø§Ù„Ø¹Ø§Ù…ÙŠØ©
- 2 Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ²ÙŠ (Ø¹Ø±Ø¨ÙŠ Ø¨Ø­Ø±ÙˆÙ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø«Ù„: "kif asajel")
- 2 Ø§Ø®ØªØµØ§Ø±Ø§Øª Ø£Ùˆ Ø£Ø®Ø·Ø§Ø¡ Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©

10 Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªØ¹Ø§Ø±Ø© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©:
- 3 ØµÙŠØº Ø±Ø³Ù…ÙŠØ©
- 3 ØµÙŠØº Ø¹Ø§Ù…ÙŠØ©/Ù…Ø®ØªØµØ±Ø©
- 2 Ø£Ø®Ø·Ø§Ø¡ Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
- 2 Ø§Ø®ØªØµØ§Ø±Ø§Øª

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØµØ§Ø±Ù…Ø©:
- ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ù…ØªØ¹Ù„Ù‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
- Ù„Ø§ ØªÙƒØ±Ø± Ø£ÙŠ Ø§Ø³Ù…
- Ø§Ø¬Ø¹Ù„Ù‡Ø§ ÙˆØ§Ù‚Ø¹ÙŠØ© (Ø£Ø´ÙŠØ§Ø¡ ÙŠÙ…ÙƒÙ† Ù„Ù„Ø·Ø§Ù„Ø¨ Ø£Ù† ÙŠÙƒØªØ¨Ù‡Ø§ ÙØ¹Ù„Ø§Ù‹)
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ©

Ø£Ø¹Ø¯ JSON Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„ Ø¨Ø§Ù„Ø¶Ø¨Ø·:
{{
    "arabic_aliases": ["Ø§Ø³Ù…1", "Ø§Ø³Ù…2", "Ø§Ø³Ù…3", "Ø§Ø³Ù…4", "Ø§Ø³Ù…5", "Ø§Ø³Ù…6", "Ø§Ø³Ù…7", "Ø§Ø³Ù…8", "Ø§Ø³Ù…9", "Ø§Ø³Ù…10"],
    "english_aliases": ["alias1", "alias2", "alias3", "alias4", "alias5", "alias6", "alias7", "alias8", "alias9", "alias10"]
}}"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ¹Ø§Ø±Ø© Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ©.
ØªÙÙ‡Ù… Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.
ØªÙˆÙ„Ø¯ Ø£Ø³Ù…Ø§Ø¡ ÙˆØ§Ù‚Ø¹ÙŠØ© ÙŠÙ…ÙƒÙ† Ù„Ù„Ø·Ù„Ø§Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙØ¹Ù„Ø§Ù‹."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            aliases = []
            
            # Collect Arabic aliases
            if 'arabic_aliases' in result:
                aliases.extend(result['arabic_aliases'][:10])
            
            # Collect English aliases  
            if 'english_aliases' in result:
                aliases.extend(result['english_aliases'][:10])
            
            # Fallback for different response formats
            if not aliases:
                if isinstance(result, list):
                    aliases = result[:20]
                elif 'aliases' in result:
                    aliases = result['aliases'][:20]
                else:
                    for value in result.values():
                        if isinstance(value, list):
                            aliases.extend(value)
                    aliases = aliases[:20]
            
            self.logger.info(f"Generated {len(aliases)} aliases for {canonical_key}")
            return aliases
            
        except Exception as e:
            self.logger.error(f"AI alias generation failed: {e}")
            return []
    
    def generate_canonical_key(self, query: str) -> str:
        """
        Generate a professional canonical key for a query using AI.
        
        Args:
            query: The user query
            
        Returns:
            A professional canonical key (snake_case, English)
        """
        if not self.client:
            return "general"
        
        try:
            prompt = f"""Generate a canonical key for this university query.

Query: "{query}"

RULES:
1. Return a single snake_case key in English
2. Key should be specific and descriptive
3. Key should be 2-4 words max
4. Examples: "course_registration", "tuition_fees", "admission_requirements", "academic_calendar"
5. DO NOT use "general" - always be specific

Return JSON:
{{"canonical_key": "your_key_here"}}"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You generate canonical keys for a university information system. Keys must be specific, descriptive, and in snake_case English."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            key = result.get('canonical_key', 'general')
            
            # Ensure it's valid
            key = key.lower().replace(' ', '_').replace('-', '_')
            if not key or key == 'general':
                # Generate from query
                words = query.lower().split()[:3]
                key = '_'.join(w for w in words if w.isalnum())[:30] or 'query'
            
            self.logger.info(f"Generated canonical key: {key} for query: {query[:50]}...")
            return key
            
        except Exception as e:
            self.logger.error(f"Canonical key generation failed: {e}")
            return "general"
